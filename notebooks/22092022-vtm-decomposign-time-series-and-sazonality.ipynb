{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decomposing the Time Series and Inspecting its Seasonality\n",
    "\n",
    "The previous [notebook](1.0-vtm-initial-data-exploration.ipynb) led us to believe that there are seasonal aspects to the time data, since it is basically the wet and dry season of a specific location.\n",
    "\n",
    "Here we'll analyze the data in three distinc granularities:\n",
    "\n",
    "- Monthly\n",
    "- Weekly\n",
    "- Daily\n",
    "\n",
    "The unstructured data was changed and altered on LibreOffice Calc - since the original raw data was obtained in this format - the three outputs are three time series, one for each of the scales mentioned early. From these series, we'll evalute their seasonality and noise.\n",
    "\n",
    "Let's load the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Time Series decomposition libraries\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTHLY_DATA_PATH = os.path.abspath(r\"..\\data\").replace('\\\\','/') + '/processed/monthly_rainfall.xlsx'\n",
    "WEEKLY_DATA_PATH = os.path.abspath(r\"..\\data\").replace('\\\\','/') + '/processed/weekly_rainfall_avg.xlsx'\n",
    "DAILY_DATA_PATH = os.path.abspath(r\"..\\data\").replace('\\\\','/') + '/processed/daily_rainfall.xlsx'\n",
    "\n",
    "monthly_df = pd.read_excel(MONTHLY_DATA_PATH, \n",
    "                           index_col=[0],\n",
    "                           parse_dates=[0])\n",
    "\n",
    "weekly_df = pd.read_excel(WEEKLY_DATA_PATH,\n",
    "                          index_col=[0],\n",
    "                          parse_dates=[0])\n",
    "\n",
    "daily_df = pd.read_excel(DAILY_DATA_PATH,\n",
    "                         index_col=[0], \n",
    "                         parse_dates=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the monthly series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe columns look ok. Since we are measuring the months from 2014 to 2021, we should have __96__ months in total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No problems. Let's proceed to plotting the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_df.plot(figsize=(15,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's clearly a cycle each year, as expected. With rainfall peaking during the southern hemisphere'sÂ¹ Spring and Summer (September to March), and plummeting during the southern hemisphere's Fall and Winter (April to August). In a sense, we can correlate these peaks and troughs with the already established wet and dry seasons for this particular region.\n",
    "\n",
    "With this information at hand, let's decompose the series to study its seasonality and noise better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decompose_monthly_rainfall = seasonal_decompose(monthly_df)\n",
    "\n",
    "decompose_monthly_rainfall.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weekly data is a bit tricky to work with - it needed to be separated not by common dates but by bloks of 7 days, rendering the date format useless. This problem was circumvented by assignin an interger number to each week, meaning that the higher the week number is, the farther in the date the series is. Another relavant point is that the monthly data includes the years 2014 and 2015, however, there's no daily data for these two years. The next series, weekly and daily, will only encompass the time period between 2016 and 2021.\n",
    "\n",
    "Let's plot the weekly rainfall average along the years - the series must contain 313 weeks (six full years in total):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_df.shape\n",
    "\n",
    "# Dataset size looks ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_df.plot(figsize=(30,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that the weekly data is much, much noisier. Let's try and decompose it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decompose_weekly_rainfall = seasonal_decompose(weekly_df)\n",
    "\n",
    "\n",
    "decompose_weekly_rainfall.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the weekly trend is similar to the monthly one, albeit with much more noise. Seasonality looks promising, with much more detail in the weekly series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's take a look at the daily data. It's possibily the noisiest of the three, and probably the most difficult one to extract information; hopefully, we'll see an improvement in the seasonality detail and a matching trend.\n",
    "\n",
    "Again, the dialy data ranges from the years 2016 to 2021, so this will give us 2192 days. Let's check the dataset's size and plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df.plot(figsize=(20,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleary the data is the noisiest (as expected), but we can discern the same yearly periods (wet and sry seasons) very precisely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decompose_daily_rainfall = seasonal_decompose(daily_df)\n",
    "\n",
    "decompose_daily_rainfall.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the seasonality becomes an irrelevant data in a daily series. The trend is also basically the same as the year. This might be a case of too much granularity of data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "285d32a9325023b05f3f70004c98a00b062085d31139aac74509f20b4434c8a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
